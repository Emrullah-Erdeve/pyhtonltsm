import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
#%%  import data

import csv
df = pd.read_csv("hava_durumu.csv", delimiter=";", quoting=csv.QUOTE_NONE, encoding='utf-8')

df = df.dropna()
df["P0"] = df["P0"].str.replace(',', '.').astype(float)
df["P"] = df["P"].str.replace(',', '.').astype(float)
df["C"] = df["C"].str.replace(',', '.').astype(float)
df["VV.1"] = df["VV.1"].str.replace(',', '.').astype(float)
df["U"] = df["U"].str.replace(',', '.').astype(float)
df["Td"] = df["Td"].str.replace(',', '.').astype(float)
#%%  import data
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA   # PCA import edilmiştir
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from imblearn.over_sampling import SMOTE
    
# Eksik değerleri düşürelim
df = df.dropna()

# PCA ve diğer işlemleri burada gerçekleştirin
y_labels = df["main"].values
y = pd.Categorical(y_labels)
y_labels = y.codes
x_ = df.drop(["main", "ADANA", "c", "VV", "id"], axis=1)

# MinMaxScaler'ı kullanarak verileri normalize edelim
scaler = MinMaxScaler()
x_scaled = scaler.fit_transform(x_)

pca = PCA(n_components=2)
x_pca = pca.fit_transform(x_scaled)

# PCA sonuçlarını DataFrame'e dönüştürelim
x_pca_df = pd.DataFrame(x_pca, columns=['PC1', 'PC2'])
x_pca_df['ID'] = range(1, len(df) + 1)

# "ID" sütununu indeks olarak ayarlayalım
x_pca_df.set_index('ID', inplace=True)
#%% 

from imblearn.over_sampling import SMOTE

x_train, x_test, y_train, y_test = train_test_split(x_pca_df, y_labels, test_size=0.2, random_state=42)

smote = SMOTE(random_state=30)
x_train_balanced, y_train_balanced = smote.fit_resample(x_train, y_train)

# x_train ve x_test verilerini tekrar 3 boyutlu tensörlere dönüştürelim (SMOTE sonrası veriler)
x_train_balanced = x_train_balanced.values.reshape(x_train_balanced.shape[0], x_train_balanced.shape[1], 1)
x_test = x_test.values.reshape(x_test.shape[0], x_test.shape[1], 1)

# Modeli oluşturalım
model = Sequential()
model.add(LSTM(30, input_shape=(x_train_balanced.shape[1], x_train_balanced.shape[2])))
model.add(Dense(1, activation='sigmoid'))

# Modeli derleyelim
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

y_train_balanced_series = pd.Series(y_train_balanced)
history = model.fit(x_train_balanced, y_train_balanced, epochs=50, batch_size=16, validation_data=(x_test, y_test))

# ... (rest of the code)


#%% 

# Eğitim ve doğrulama doğruluk değerlerini elde edelim
train_accuracy = history.history['loss']
val_accuracy = history.history['val_loss']

# Epoch sayısını elde edelim
epochs = range(1, len(train_accuracy) + 1)


# Grafik çizimi
plt.plot(epochs, train_accuracy, 'b', label='loss')
plt.plot(epochs, val_accuracy, 'r', label='val_loss')
plt.title('Eğitim ve Doğrulama Doğruluk')
plt.xlabel('Epochs')
plt.ylabel('Doğruluk')

plt.legend()
plt.show()
#%% 
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from sklearn.metrics import confusion_matrix

# Step 1: Predict probabilities for the positive class (class 1) on the validation data
y_prob = model.predict(x_test)

# Step 2 and 3: Calculate TPR and FPR for each threshold
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

# Step 4: Plot the ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

# Step 5: Find the optimal threshold
optimal_threshold_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_threshold_idx]

print("Optimal Threshold:", optimal_threshold)
y_pred = model.predict(x_test)
threshold = 0.68
y_pred_classes = (y_pred > threshold).astype(int)

# Confusion matrix oluştur
confusion_mat = confusion_matrix(y_test, y_pred_classes)

# Confusion matrix'i ekrana yazdır
print("Confusion Matrix:")
print(confusion_mat)

# Confusion matrix'i görselleştir (opsiyonel)
import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(confusion_mat, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()
